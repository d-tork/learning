# Databricks Flight School
"Partner Solutions Architect Essentials"

The third coding assignment in the capstone project (MLflow) is about using the API, not about the
machine learning.

## Questions
* I keep seeing that data lakes can store unstructured data such as videos and images, but I have
yet to see an example of an ETL pipeline that uses them. Are the binary files themselves stored 
in parquet as a column? What transformation is applied in order to get data out of them, such as
color and pixel data, frames of a video, encoding, EXIF data, runtime? And is that done at the
silver stage of the Delta architecture? 
	- And what if the format is proprietary, like PDF or DOCX? 
	- Louis will send me an example notebook
	- https://databricks.com/solutions/accelerators
* What is the proprietary Delta Engine competing against? Just the plain Spark engine? Are there
other efforts to optimize the spark engine? (i.e. Snowflake?)
	- Amazon EMR has an "optimized" version of Spark
* [MLflow] Are experiments and notebooks synonymous? As in, there is always a 1:1 relationship, or
can you create multiple experiments in the same notebook?
	- No, with the API you can create experiments at will 
	- https://www.mlflow.org/docs/latest/tracking.html#organizing-runs-in-experiments
* How much of a performance hit are we taking by using Pandas? I assume almost none of the benefits
of Delta Tables, Delta Engine, or Spark are being leveraged.
	- depends on the size of your dataset (for tiny files, doesn't matter)
* I noticed that in the Autogenerated Inference notebook, it installs dependencies via pip instead
of conda and says that conda was in use for Databricks Runtime 7.4-8.x. Are they moving away from 
conda environments in the MLflow projects structure now?
	- Lou will get back to me

## Setting up the CLI
https://docs.microsoft.com/en-us/azure/databricks/dev-tools/cli/

### Getting an Azure AD token for `databricks-cli`
https://docs.microsoft.com/en-us/azure/databricks/dev-tools/api/latest/aad/app-aad-token

```yaml
Application (client) ID: d7005d6c-9a9a-4a8d-ae6c-17de8b8d6b07
Directory (tenant) ID: 5c7fb37f-32ac-4c1f-b68f-8333b63a6a00
Redirect URI: http://localhost
```

URL for requesting an auth code
```
https://login.microsoftonline.com/5c7fb37f-32ac-4c1f-b68f-8333b63a6a00/oauth2/v2.0/authorize?client_id=d7005d6c-9a9a-4a8d-ae6c-17de8b8d6b07
&response_type=code
&redirect_uri=http%3A%2F%2Flocalhost
&response_mode=query
&scope=2ff814a6-3304-4ab8-85cb-cd0e6f879c1d%2F.default
&state=69
```

Auth code:
```
0.AUYAf7N_XKwyH0y2j4MztjpqAGxdANeamo1KrmwX3ouNawdGADM.AQABAAIAAAD--DLA3VO7QrddgJg7WevrnKwHQeVTOciUcMk4gCHtcRecAnLuQkgqB5pt8OF7bgMwwdIl8L2IBGZXvSDqsIoJPmmno_FHsC_b_uFYnjB_WZmrAd1GpF95xag9PNvVM6vYBAB44fDNMDwGxJem6uNfyKd_RA1Q2WCx8VulD87LULCpxqLDigf6ZyvVYiGaUqPFrslmecq9ao4hmJdlSf0U9vuMxCmapcbEpGhwhJ5gjJkYDVHoGebkfJpfJmxDrBu3DKB5T0nC8_G547U3_1v2EafgKOPfZuQtKhDnY-Pfg8fgTUmmVs4ile2WSAoiLGqYWua3KT_Q7wYztj_mL4eOhm5Skj4fzEcQ_QfHIBx45KtWR3yZEGWmsBRxRKiYNQ9hx-IU8T_bQI5aQwmSuldsxAK9KCT7bk7JnROImlbGAHQk8OWkWnNwmzKJR8Og7kwedVqZMtTplAbe4V8iIftz_kY316q_d39A3hLJ9WNKThZ_icJljnWWSzO5G4GtvJOlYYxpo5ZKhOLE2xj5xrwMMYpYAPctH9DdF9QlfaVOZGu83ZkfzvHCDXsniWMRdsofBui_qXVwEulnVeVLoKLaRC_gq2qnsU94_JOJeFxauBeAYWaMZg5Q5OS_rOB99iF_xdMXbPJox_0pdTXQehgJGdXPl6nOJ_CIJK00ANJtI_e3jZspOWDpDtaU6nVN5HctSRY_qAORc4hPCDS6BQuWK08gd2YZNV23XYDJYb88MSAA
```

Command for getting a token
```bash
curl -X POST -H 'Content-Type: application/x-www-form-urlencoded' \
https://login.microsoftonline.com/5c7fb37f-32ac-4c1f-b68f-8333b63a6a00/oauth2/v2.0/token \
-d 'client_id=d7005d6c-9a9a-4a8d-ae6c-17de8b8d6b07' \
-d 'scope=2ff814a6-3304-4ab8-85cb-cd0e6f879c1d%2F.default' \
-d 'code=0.AUYAf7N_XKwyH0y2j4MztjpqAGxdANeamo1KrmwX3ouNawdGADM.AQABAAIAAAD--DLA3VO7QrddgJg7WevrnKwHQeVTOciUcMk4gCHtcRecAnLuQkgqB5pt8OF7bgMwwdIl8L2IBGZXvSDqsIoJPmmno_FHsC_b_uFYnjB_WZmrAd1GpF95xag9PNvVM6vYBAB44fDNMDwGxJem6uNfyKd_RA1Q2WCx8VulD87LULCpxqLDigf6ZyvVYiGaUqPFrslmecq9ao4hmJdlSf0U9vuMxCmapcbEpGhwhJ5gjJkYDVHoGebkfJpfJmxDrBu3DKB5T0nC8_G547U3_1v2EafgKOPfZuQtKhDnY-Pfg8fgTUmmVs4ile2WSAoiLGqYWua3KT_Q7wYztj_mL4eOhm5Skj4fzEcQ_QfHIBx45KtWR3yZEGWmsBRxRKiYNQ9hx-IU8T_bQI5aQwmSuldsxAK9KCT7bk7JnROImlbGAHQk8OWkWnNwmzKJR8Og7kwedVqZMtTplAbe4V8iIftz_kY316q_d39A3hLJ9WNKThZ_icJljnWWSzO5G4GtvJOlYYxpo5ZKhOLE2xj5xrwMMYpYAPctH9DdF9QlfaVOZGu83ZkfzvHCDXsniWMRdsofBui_qXVwEulnVeVLoKLaRC_gq2qnsU94_JOJeFxauBeAYWaMZg5Q5OS_rOB99iF_xdMXbPJox_0pdTXQehgJGdXPl6nOJ_CIJK00ANJtI_e3jZspOWDpDtaU6nVN5HctSRY_qAORc4hPCDS6BQuWK08gd2YZNV23XYDJYb88MSAA' \
-d 'redirect_uri=http%3A%2F%2Flocalhost' \
-d 'grant_type=authorization_code' \
-d 'state=69'
```
Store the output of that curl as a JSON (like `auth_code.json`)

Then set it as the env variable, and configure databricks 
```bash
export DATABRICKS_AAD_TOKEN=$(cat auth_code.json | jq .access_token --raw-output)
databricks configure --aad-token
```

## Capstone Project
* due EOD Monday Mar 14
* export each notebook to HTML
* zip the three files
* put your name in the zip file 
	- Daniel.Torkelson-solution_arch_essentials.zip

### Turn in:
Academy > Content > Technical Depth Assignment > drop the zip file

## Extra gold analytics - Coding exercise 1
* turn one or more of them into a visualization
* (I hate this but) think of a scatter plot or two that could be useful

## Assignment 2
```python
out_stream.writeStream \
          <TO DO... how can you write the windowed aggregation?
          .table("readings_agg")
```
